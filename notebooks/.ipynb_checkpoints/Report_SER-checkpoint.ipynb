{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not spend too much time trying to get very tiny metrics improvement. Once you have a model with a correct predictive power, you should better spend time explaining your data cleaning & preparation pipeline as well as explanations & visualizations of the results.\n",
    "\n",
    "The goal is to see your fit with our company culture & engineering needs, spending 50h on an over-complicated approach will not give you bonus points compared to a simple, yet effective, to-the-point solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset you will be working with is called Emo-DB and can be found [here](http://emodb.bilderbar.info/index-1280.html).\n",
    "\n",
    "It is a database containing samples of emotional speech in German. It contains samples labeled with one of 7 different emotions: Anger, Boredom, Disgust, Fear, Happiness, Sadness and Neutral. \n",
    "\n",
    "Please download the full database and refer to the documentation to understand how the samples are labeled (see \"Additional information\")\n",
    "   \n",
    "The goal of this project is to develop a model which is able to **classify samples of emotional speech**. Feel free to use any available library you would need, but beware of re-using someone else's code without mentionning it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end-goal is to deliver us a zip file containing:\n",
    "* This report filled with your approach, in the form of an **iPython Notebook**.\n",
    "* A **5-10 slides PDF file**, containing a technical presentation covering the important aspects of your work\n",
    "* A Dockerfile which defines a container for the project. The container should handle everything (download the data, run the code, etc...). When running the container it should expose the jupyter notebook on one port and expose a Flask API on another one. The Flask app contains two endpoints:\n",
    "  - One for training the model\n",
    "  - One for querying the last trained model with an audio file of our choice in the dataset\n",
    "* A README.md which should contain the commands to build and run the docker container, as well as how to perform the queries to the API. \n",
    "* Any necessary .py, .sh or other files needed to run your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc, logfbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Flatten, LSTM\n",
    "from keras.layers import Dropout, Dense, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('../data/wav/03a01Fa.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is mono (1 channel)\n",
    "print(data.shape)\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "plt.title('time domain signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recording device has a \"bit depth\" (eg. 16) => signal can take 2^bit_depth possible values.  \n",
    "Go from time domain to frequency domain (periodogram/power spectral density estimate) with FFT.  \n",
    "Periodogram goes to 22.5 kHz, but audio is typically recorded at 44.1 kHz. The Nyquist freq is 44.1 / 2 = 22.5 kHz is the highest freq from the environment we can represent (eg. 30 kHz can't represented).  \n",
    "Usually downsample audio to 16 kHz (most info is below 8 kHz which is the Nyquist freq).  \n",
    "\n",
    "Spectrogram: stacking periodograms over time (freq vs time) => obtain images with pixel intensities representing frequencies => 2d input format.\n",
    "\n",
    "Use Short Time Fourier Transform: take small intervals of audio, assume stationarity, take window size of 25 ms (standard), slide window forward 10 ms, use Hanning window for FFT computation to avoid spectral leakage => obtain 2d images with signatures for each sound.\n",
    "\n",
    "https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html\n",
    "\n",
    "Mel scale: as humans easy to tell apart low freqs (10 vs 10 Hz), but difficult for high freqs (15'000 vs 15'100 Hz) => scale freqs with log (re-bin freqs) => care about diffs in small freqs not diffs in large freqs => use filter bank (26 triangular filters to bin energies) => build input features based on power spectral density (image of size 26x100 for 1s of data).\n",
    "\n",
    "http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "\n",
    "DCT: STFT has overlap in samples => correlated samples => decorrelate samples (DCT on filter bank energies) and get 26x100 samples again => usually take 13 first MFCCs since only interested in low freqs (discard the rest).\n",
    "\n",
    "http://datagenetics.com/blog/november32012/index.html\n",
    "\n",
    "See https://www.youtube.com/watch?v=Z7YM-HAz-IY for slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/wav'\n",
    "df = os.listdir(path)\n",
    "print(df[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = [file[:2] for file in df]\n",
    "text = [file[2:5] for file in df]\n",
    "print(text[:5])\n",
    "emotion = [file[5] for file in df]\n",
    "print(emotion[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df, columns=['filename'])\n",
    "df['speaker'] = speaker\n",
    "df['text'] = text\n",
    "df['emotion'] = emotion\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(df.emotion)\n",
    "num_classes = len(classes)\n",
    "print(classes)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(df.filename, inplace=True)\n",
    "for file in df.index:\n",
    "    rate, signal = wavfile.read(f'{path}/{file}')\n",
    "    df.at[file, 'length'] = signal.shape[0] / rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_count_by_class = df.groupby('emotion')['filename'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_count_by_class_pct = emotion_count_by_class / emotion_count_by_class.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_count_by_class_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Pct of samples by class')\n",
    "ax.pie(emotion_count_by_class_pct, labels=emotion_count_by_class_pct.index, autopct='%1.1f%%',\n",
    "      shadow=False, startangle=90)\n",
    "ax.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "#df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More or less evenly distributed => maybe will need to correct for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sample_length_by_class = df.groupby('emotion')['length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sample_length_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(np.arange(num_classes), avg_sample_length_by_class)\n",
    "ax.set_ylabel('Avg Sample Length')\n",
    "ax.set_xticks(np.arange(num_classes))\n",
    "ax.set_xticklabels(classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.markeredgecolor'] = 'black'\n",
    "mpl.rcParams['hist.bins'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "df['length'].hist(by=df['emotion'], xrot=0, ax=ax1, bins=20, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "df['length'].hist(by=df['speaker'], xrot=0, ax=ax1, bins=20, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "df['length'].hist(by=df['text'], xrot=0, ax=ax1, bins=20, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('emotion')['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('emotion')['speaker'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('emotion')['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "df['speaker'].hist(by=df['emotion'], xrot=0, ax=ax1, bins=20, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "df['speaker'].hist(by=df['text'], xrot=0, ax=ax1, bins=20, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "df['emotion'].hist(by=df['speaker'], , xrot=0, ax=ax1, bins=20, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "df['emotion'].hist(by=df['text'], , xrot=0, ax=ax1, bins=20, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "df['emotion'].hist(by=df['length'], , xrot=0, ax=ax1, bins=20, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = []\n",
    "for file in df.filename:\n",
    "    sr, _ = wavfile.read(f'{path}/{file}')\n",
    "    rate.append(sr)\n",
    "    \n",
    "np.unique(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 16 kHz audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {'W': 'Arger (Wut)',\n",
    "            'L': 'Langeweile',\n",
    "            'E': 'Ekel',\n",
    "            'A': 'Angst',\n",
    "            'F': 'Freude',\n",
    "            'T': 'Trauer',\n",
    "            'N': 'Neutral'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/wav'\n",
    "\n",
    "lst = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    \n",
    "    data, sampling_rate = librosa.load(os.path.join(path, file), res_type='kaiser_fast')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "    file = file.strip('.wav')\n",
    "    arr = mfccs, file[5]\n",
    "    lst.append(arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = zip(*lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(y)\n",
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((535, 40), (535,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, array(['A', 'E', 'F', 'L', 'N', 'T', 'W'], dtype='<U1'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(y)\n",
    "num_classes = len(np.unique(y))\n",
    "num_classes, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 40) (54, 40) (97, 40)\n",
      "(384,) (54,) (97,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code emporium video: https://www.youtube.com/watch?v=GNza2ncnMfA  \n",
    "see also his code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search/hyperparam optimization/CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "train_samples = X_train.shape[0]\n",
    "# Turn up tolerance for faster convergence\n",
    "clf = LogisticRegression(\n",
    "    C=50. / train_samples, penalty='l1', solver='saga', tol=0.1\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "sparsity = np.mean(clf.coef_ == 0) * 100\n",
    "score = clf.score(X_test, y_test)\n",
    "# print('Best C % .4f' % clf.C_)\n",
    "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0].reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(predictions == y_test)\n",
    "print('accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(dtree, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/dtree.pkl', 'wb') as model_pkl:\n",
    "    pickle.dump(dtree, model_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/dtree.pkl', 'rb') as model_pkl:\n",
    "    dtree = pickle.load(model_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 40)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.31800705e+02,  1.45115952e+02, -4.18604736e+01,  5.64334908e+01,\n",
       "       -1.88243828e+01,  2.33389740e+01,  1.26841068e-01, -1.27366648e+01,\n",
       "       -2.15315628e+00, -1.79241168e+00,  4.84273815e+00, -1.18137522e+01,\n",
       "        3.10706806e+00,  3.77017522e+00, -7.80684054e-01, -8.34174919e+00,\n",
       "        1.24492295e-01, -4.43314743e+00, -3.25039601e+00,  3.63110590e+00,\n",
       "       -4.66818380e+00,  4.52625084e+00, -9.66896057e-01,  1.18457846e-01,\n",
       "       -1.77504265e+00, -7.78974712e-01,  2.95195580e+00, -2.79300785e+00,\n",
       "        2.06982589e+00, -1.86556375e+00, -3.62887216e+00, -1.03186083e+00,\n",
       "       -1.95707917e+00,  3.64466667e-01,  4.25815153e+00,  4.55306292e+00,\n",
       "        5.64278936e+00,  4.04408646e+00,  1.72497976e+00,  1.54143500e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N'], dtype='<U1')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.predict(X_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'W'], dtype='<U1')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.predict(X_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['N' 'W']\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dtree.predict(X_test[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier(criterion='gini', max_depth=10, max_features='log2',\n",
    "                                max_leaf_nodes=100, min_samples_leaf=3, min_samples_split=20,\n",
    "                                n_estimators=22000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(predictions == y_test)\n",
    "print('accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rforest, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(predictions == y_test)\n",
    "print('accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting/XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN conv1d - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marcogdepinto/emotion-classification-from-audio-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_valcnn = np.expand_dims(X_val, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn.shape, x_valcnn.shape, x_testcnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5, padding='same',input_shape=(40,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 'W'] = 0\n",
    "y_train[y_train == 'L'] = 1\n",
    "y_train[y_train == 'E'] = 2\n",
    "y_train[y_train == 'A'] = 3\n",
    "y_train[y_train == 'F'] = 4\n",
    "y_train[y_train == 'T'] = 5\n",
    "y_train[y_train == 'N'] = 6\n",
    "\n",
    "y_test[y_test == 'W'] = 0\n",
    "y_test[y_test == 'L'] = 1\n",
    "y_test[y_test == 'E'] = 2\n",
    "y_test[y_test == 'A'] = 3\n",
    "y_test[y_test == 'F'] = 4\n",
    "y_test[y_test == 'T'] = 5\n",
    "y_test[y_test == 'N'] = 6\n",
    "\n",
    "y_val[y_val == 'W'] = 0\n",
    "y_val[y_val == 'L'] = 1\n",
    "y_val[y_val == 'E'] = 2\n",
    "y_val[y_val == 'A'] = 3\n",
    "y_val[y_val == 'F'] = 4\n",
    "y_val[y_val == 'T'] = 5\n",
    "y_val[y_val == 'N'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../models/conv1d/model.{epoch:02d}-{accuracy:.4f}-{val_accuracy:.4f}-{loss:.4f}-{val_loss:.4f}.h5', monitor='val_loss', verbose=1, mode='min', save_best_only=True,\n",
    "                            save_weights_only=False, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(x_traincnn, y_train, batch_size=16, epochs=250, validation_data=(x_valcnn, y_val),\n",
    "#                   callbacks=[checkpoint])\n",
    "history = model.fit(x_traincnn, y_train, batch_size=16, epochs=250, validation_data=(x_valcnn, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_title('model loss')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "ax2.plot(history.history['accuracy'])\n",
    "ax2.plot(history.history['val_accuracy'])\n",
    "ax2.set_title('model accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_testcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (classes[np.argmax(predictions, axis=1)] == classes[np.argmax(y_test, axis=1)]).mean()\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(classes[np.argmax(y_test, axis=1)], classes[np.argmax(predictions, axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn_model_1.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print(f'Saved model at {model_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(40,1)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_traincnn, y_train, batch_size=16, epochs=250, validation_data=(x_valcnn, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_title('model loss')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "ax2.plot(history.history['accuracy'])\n",
    "ax2.plot(history.history['val_accuracy'])\n",
    "ax2.set_title('model accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_testcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (classes[np.argmax(predictions, axis=1)] == classes[np.argmax(y_test, axis=1)]).mean()\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(classes[np.argmax(y_test, axis=1)], classes[np.argmax(predictions, axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN conv2d - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEED STEREO WAV FILE (2 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(438, 40, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(8, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_traincnn, y_train, batch_size=16, epochs=250, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Seth Adams - OLD VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/seth814/Audio-Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python_speech_features lib from James Lyons of practical cryptography: https://github.com/jameslyons/python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signals(signals):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4, sharex=False,\n",
    "                             sharey=True, figsize=(20,5))\n",
    "    axes = axes.ravel()\n",
    "    fig.suptitle('Time Series', size=16)\n",
    "    \n",
    "    for i in range(len(signals)):\n",
    "        axes[i].set_title(list(signals.keys())[i])\n",
    "        axes[i].plot(list(signals.values())[i])\n",
    "        axes[i].get_xaxis().set_visible(False)\n",
    "        axes[i].get_yaxis().set_visible(False)\n",
    "    fig.delaxes(axes[-1])\n",
    "    '''\n",
    "    i = 0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            axes[x,y].set_title(list(signals.keys())[i])\n",
    "            axes[x,y].plot(list(signals.values())[i])\n",
    "            axes[x,y].get_xaxis().set_visible(False)\n",
    "            axes[x,y].get_yaxis().set_visible(False)\n",
    "            i += 1\n",
    "    '''\n",
    "\n",
    "def plot_fft(fft):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4, sharex=False,\n",
    "                             sharey=True, figsize=(20,5))\n",
    "    fig.suptitle('Fourier Transforms', size=16)\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(len(fft)):\n",
    "        data = list(fft.values())[i]\n",
    "        Y, freq = data[0], data[1]\n",
    "        axes[i].set_title(list(fft.keys())[i])\n",
    "        axes[i].plot(freq, Y)\n",
    "        axes[i].get_xaxis().set_visible(False)\n",
    "        axes[i].get_yaxis().set_visible(False)\n",
    "    fig.delaxes(axes[-1])\n",
    "    \n",
    "    '''\n",
    "    i = 0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            data = list(fft.values())[i]\n",
    "            Y, freq = data[0], data[1]\n",
    "            axes[x,y].set_title(list(fft.keys())[i])\n",
    "            axes[x,y].plot(freq, Y)\n",
    "            axes[x,y].get_xaxis().set_visible(False)\n",
    "            axes[x,y].get_yaxis().set_visible(False)\n",
    "            i += 1\n",
    "    '''\n",
    "    \n",
    "def plot_fbank(fbank):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4, sharex=False,\n",
    "                             sharey=True, figsize=(20,5))\n",
    "    fig.suptitle('Filter Bank Coefficients', size=16)\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(len(fbank)):\n",
    "        axes[i].set_title(list(fbank.keys())[i])\n",
    "        axes[i].imshow(list(fbank.values())[i],\n",
    "                        cmap='hot', interpolation='nearest')\n",
    "        axes[i].get_xaxis().set_visible(False)\n",
    "        axes[i].get_yaxis().set_visible(False)\n",
    "    fig.delaxes(axes[-1])\n",
    "    \n",
    "    '''\n",
    "    i = 0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            axes[x,y].set_title(list(fbank.keys())[i])\n",
    "            axes[x,y].imshow(list(fbank.values())[i],\n",
    "                    cmap='hot', interpolation='nearest')\n",
    "            axes[x,y].get_xaxis().set_visible(False)\n",
    "            axes[x,y].get_yaxis().set_visible(False)\n",
    "            i += 1\n",
    "    '''\n",
    "    \n",
    "def plot_mfccs(mfccs):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4, sharex=False,\n",
    "                             sharey=True, figsize=(20,5))\n",
    "    fig.suptitle('Mel Frequency Cepstrum Coefficients', size=16)\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(len(mfccs)):\n",
    "        axes[i].set_title(list(mfccs.keys())[i])\n",
    "        axes[i].imshow(list(mfccs.values())[i],\n",
    "                cmap='hot', interpolation='nearest')\n",
    "        axes[i].get_xaxis().set_visible(False)\n",
    "        axes[i].get_yaxis().set_visible(False)\n",
    "    fig.delaxes(axes[-1])\n",
    "        \n",
    "    '''i = 0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            axes[x,y].set_title(list(mfccs.keys())[i])\n",
    "            axes[x,y].imshow(list(mfccs.values())[i],\n",
    "                    cmap='hot', interpolation='nearest')\n",
    "            axes[x,y].get_xaxis().set_visible(False)\n",
    "            axes[x,y].get_yaxis().set_visible(False)\n",
    "            i += 1'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fft(y, rate):\n",
    "    n = len(y)\n",
    "    freq = np.fft.rfftfreq(n, d=1/rate)\n",
    "    Y = abs(np.fft.rfft(y)/n)\n",
    "    return (Y, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = {}\n",
    "fft = {}\n",
    "fbank = {}\n",
    "mfccs = {}\n",
    "\n",
    "for c in classes:\n",
    "    wav_file = df[df.emotion == c]['filename'].iloc[0]\n",
    "    signal, rate = librosa.load(f'{path}/{wav_file}', sr=16000)\n",
    "    signals[c] = signal\n",
    "    fft[c] = calc_fft(signal, rate)\n",
    "    \n",
    "    # only take one second of signal\n",
    "    #Â 16000/40=400 : since we take 25ms windows, 1s/40=0.025s\n",
    "    bank = logfbank(signal[:rate], rate, nfilt=26, nfft=400).T\n",
    "    fbank[c] = bank\n",
    "    \n",
    "    # numcep: nb of cepstrals we keep after DCT => throw away 50%\n",
    "    mel = mfcc(signal[:rate], rate, numcep=13, nfilt=26, nfft=400).T\n",
    "    mfccs[c] = mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signals(signals)\n",
    "plt.show()\n",
    "\n",
    "plot_fft(fft)\n",
    "plt.show()\n",
    "\n",
    "plot_fbank(fbank)\n",
    "plt.show()\n",
    "\n",
    "plot_mfccs(mfccs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can do noise threshold detection (Filtering): remove parts of audio with no sound => to keep only characteristic signal of each class\n",
    "- FFT: can distinguish differences but not optimal\n",
    "- Filterbank energies: patterns emerge (temporal relationships)\n",
    "- DCT: plots are a lot more unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove audio \"deadspace\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to compute envelope of the signal: estimation of signal magnitude, if signal too low below envelope we consider the audio has died out and remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def envelope(y, rate, threshold):\n",
    "    mask = []\n",
    "    y = pd.Series(y).apply(np.abs)\n",
    "    y_mean = y.rolling(window=int(0.1*rate), min_periods=1, center=True).mean()\n",
    "    for mean in y_mean:\n",
    "        if mean > threshold:\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            mask.append(False)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = {}\n",
    "fft = {}\n",
    "fbank = {}\n",
    "mfccs = {}\n",
    "\n",
    "for c in classes:\n",
    "    wav_file = df[df.emotion == c]['filename'].iloc[0]\n",
    "    signal, rate = librosa.load(f'{path}/{wav_file}', sr=16000)\n",
    "    mask = envelope(signal, rate, 0.0005)\n",
    "    signal = signal[mask]\n",
    "    signals[c] = signal\n",
    "    fft[c] = calc_fft(signal, rate)\n",
    "    \n",
    "    # only take one second of signal\n",
    "    #Â 16000/40=400 : since we take 25ms windows, 1s/40=0.025s\n",
    "    bank = logfbank(signal[:rate], rate, nfilt=26, nfft=400).T\n",
    "    fbank[c] = bank\n",
    "    \n",
    "    # numcep: nb of cepstrals we keep after DCT => throw away 50%\n",
    "    mel = mfcc(signal[:rate], rate, numcep=13, nfilt=26, nfft=400).T\n",
    "    mfccs[c] = mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signals(signals)\n",
    "plt.show()\n",
    "\n",
    "plot_fft(fft)\n",
    "plt.show()\n",
    "\n",
    "plot_fbank(fbank)\n",
    "plt.show()\n",
    "\n",
    "plot_mfccs(mfccs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean audio and move to 'clean' dir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can try to downsample more (eg. 8 kHz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(os.listdir('../data/clean')) == 0:\n",
    "    for f in tqdm(df.filename):\n",
    "        signal, rate = librosa.load(f'{path}/{f}', sr=16000)\n",
    "        mask = envelope(signal, rate, 0.0005)\n",
    "        wavfile.write(filename=f'../data/clean/{f}', rate=rate, data=signal[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sample 1s chunks out of audio => don't take entire signal sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2 * int(df['length'].sum() / 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from cfg import Config  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('filename', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rand_feat():\n",
    "    tmp = check_data()\n",
    "    if tmp:\n",
    "        return tmp.data[0], tmp.data[1]\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    _min, _max = float('inf'), -float('inf')\n",
    "    \n",
    "    for _ in tqdm(range(n_samples)):\n",
    "        rand_class = np.random.choice(emotion_count_by_class_pct.index, p=emotion_count_by_class_pct)\n",
    "        file = np.random.choice(df[df.emotion == rand_class].index)\n",
    "        rate, wav = wavfile.read(f'../data/clean/{file}')\n",
    "        label = df.at[file, 'emotion']\n",
    "        rand_index = np.random.randint(0, wav.shape[0]-config.step)\n",
    "        sample = wav[rand_index:rand_index+config.step]\n",
    "        X_sample = mfcc(sample, rate, numcep=config.nfeat, nfilt=config.nfilt, nfft=config.nfft)\n",
    "        _min = min(np.amin(X_sample), _min)\n",
    "        _max = max(np.amax(X_sample), _max)\n",
    "        X.append(X_sample)\n",
    "        y.append((np.where(classes == label))[0][0])\n",
    "        \n",
    "    config.min = _min\n",
    "    config.max = _max\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = (X - _min) / (_max - _min)\n",
    "    \n",
    "    if config.mode == 'conv':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    elif config.mode == 'time':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "        \n",
    "    y = to_categorical(y, num_classes=7)\n",
    "    config.data = (X, y)\n",
    "    \n",
    "    with open(config.p_path, 'wb') as handle:\n",
    "        # for compatibility with python 2: protocol=2\n",
    "        pickle.dump(config, handle, protocol=2)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y):\n",
    "    # take last 10% of data for test\n",
    "    X_test = X[int(0.9*len(X)):]\n",
    "    y_test = y[int(0.9*len(y)):]\n",
    "    #Â take remaining 80% of data for train\n",
    "    X = X[:int(0.9*len(X))]\n",
    "    y = y[:int(0.9*len(y))]\n",
    "    X_train = X[:int(0.8*len(X))]\n",
    "    y_train = y[:int(0.8*len(y))]\n",
    "    #Â take remaining 20% of data for val\n",
    "    X_val = X[int(0.8*len(X)):]\n",
    "    y_val = y[int(0.8*len(y)):]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data():\n",
    "    if os.path.isfile(config.p_path):\n",
    "        print(f'Loading existing data for {config.mode} model')\n",
    "        with open(config.p_path, 'rb') as handle:\n",
    "            tmp = pickle.load(handle)\n",
    "            return tmp\n",
    "    else:\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only pool down once because X is not high dimensional\n",
    "# should try with batch norm\n",
    "def get_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=input_shape))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_model():\n",
    "    # shape of input X for RNN: (n, time, feat)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(16, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(8, activation='relu')))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(mode='conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "if config.mode == 'conv':\n",
    "    X, y = build_rand_feat()\n",
    "    y_flat = np.argmax(y, axis=1)\n",
    "    input_shape = (X.shape[1], X.shape[2], 1)\n",
    "    model = get_conv_model()\n",
    "elif config.mode == 'time':\n",
    "    X, y = build_rand_feat()\n",
    "    y_flat = np.argmax(y, axis=1)\n",
    "    input_shape = (X.shape[1], X.shape[2])\n",
    "    model = get_recurrent_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight matrix update will put more emphasis on gradient steps for under-represented classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = compute_class_weight('balanced', np.unique(y_flat), y_flat)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(config.model_path, monitor=['val_accuracy'], verbose=1, mode='max', save_best_only=True,\n",
    "                            save_weights_only=False, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../models/run1/model.{epoch:02d}-{accuracy:.4f}-{val_accuracy:.4f}-{loss:.4f}-{val_loss:.4f}.h5', monitor='val_loss', verbose=1, mode='min', save_best_only=True,\n",
    "                            save_weights_only=False, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=250, batch_size=16, shuffle=True, validation_split=0.1, \n",
    "         callbacks=[checkpoint]) #, class_weight=class_weight)\n",
    "\n",
    "#model.save(config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(X, y, epochs=10, batch_size=16, shuffle=True, validation_data=(X_val, y_val), \n",
    "#         callbacks=[checkpoint])\n",
    "\n",
    "history = model.fit(X, y, epochs=10, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_title('model loss')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "ax2.plot(history.history['accuracy'])\n",
    "ax2.plot(history.history['val_accuracy'])\n",
    "ax2.set_title('model accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = load_model('../models/run1/model.09-0.5921-0.6578-1.0531-0.9076.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (classes[np.argmax(preds, axis=1)] == classes[np.argmax(y_test, axis=1)]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(classes[np.argmax(y_test, axis=1)], classes[np.argmax(preds, axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(classes[np.argmax(y_test, axis=1)], classes[np.argmax(preds, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â CNN - Code Emporium - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ajhalthor/audio-classifier-convNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(16, input_shape=(40, 1), activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_traincnn, y_train, batch_size=16, epochs=250, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
